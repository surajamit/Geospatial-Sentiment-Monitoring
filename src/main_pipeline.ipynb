{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819bfc63",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from training.train_rf import train_model\n",
    "from evaluation.metrics import evaluate_model\n",
    "from visualization.plots import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47080f5f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pyspark tweepy scikit-learn seaborn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b565144",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from source.spark_streaming import create_streaming_context, start_streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b441d7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sc, ssc = create_streaming_context()\n",
    "start_streaming(ssc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a93353",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/tweets.csv\")\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "test_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d4f3a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Algorithm-FUSION-SPARK:\n",
    "Real-Time Geo-Sentiment Analytics Pipeline\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StringType, IntegerType\n",
    "\n",
    "from src.preprocessing.lemma_tokenizer import lemma_tokenize\n",
    "from src.spark.spark_schema import get_twitter_schema\n",
    "from src.features.feature_selector import select_core_features\n",
    "from src.utils.tech_mapper import map_technology\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Spark Session (Spark 3.x)\n",
    "# --------------------------------------------------\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Fusion-Spark-GeoSentiment\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", 32)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Load Data from HDFS\n",
    "# --------------------------------------------------\n",
    "hdfs_path = \"hdfs://192.168.1.165:9000/user/flume/ml/\"\n",
    "\n",
    "df_raw = spark.read.json(\n",
    "    hdfs_path,\n",
    "    schema=get_twitter_schema()\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Feature Selection\n",
    "# --------------------------------------------------\n",
    "df_core = select_core_features(df_raw)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# NLP Processing\n",
    "# --------------------------------------------------\n",
    "token_udf = udf(lemma_tokenize, ArrayType(StringType()))\n",
    "tech_udf = udf(map_technology, IntegerType())\n",
    "\n",
    "df_processed = (\n",
    "    df_core\n",
    "    .withColumn(\"tokens\", token_udf(\"text\"))\n",
    "    .withColumn(\"tech_id\", tech_udf(\"text\"))\n",
    ")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Write to HDFS (CSV)\n",
    "# --------------------------------------------------\n",
    "output_path = \"hdfs://192.168.1.165:9000/user/flume/output/\"\n",
    "\n",
    "(\n",
    "    df_processed\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .csv(output_path, header=True)\n",
    ")\n",
    "\n",
    "print(\"Fusion pipeline executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10ad9a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = train_model(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e168bac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "results = evaluate_model(\n",
    "    model,\n",
    "    test_df[\"text\"],\n",
    "    test_df[\"label\"]\n",
    ")\n",
    "\n",
    "print(\"F1 Score:\", results[\"f1\"])\n",
    "plot_confusion_matrix(results[\"cm\"], [\"Neg\", \"Neu\", \"Pos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4b68d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.rf_sentiment_3class import build_rf, evaluate_rf\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "rf = build_rf()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "metrics = evaluate_rf(rf, X_test, y_test)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a4180b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = metrics[\"confusion_matrix\"]\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.xlabel(\"Predicted Lebels\")\n",
    "plt.ylabel(\"True Lebels\")\n",
    "plt.title(\"Confusion Matrix of Sentiment Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0d0225",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "y_pred = metrics[\"y_pred\"]\n",
    "\n",
    "p, r, f, _ = precision_recall_fscore_support(\n",
    "    y_test, y_pred, average=None\n",
    ")\n",
    "\n",
    "labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "x = range(len(labels))\n",
    "width = 0.25\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "\n",
    "plt.bar([i - width for i in x], p, width, label=\"Precision\")\n",
    "plt.bar(x, r, width, label=\"Recall\")\n",
    "plt.bar([i + width for i in x], f, width, label=\"F1-score\")\n",
    "\n",
    "plt.xticks(x, labels)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Per-Class Performance of RF Classifier\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Overall F1:\", metrics[\"f1_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05112df7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "=== EXPERIMENTAL VALIDATION PIPELINE ===\n",
    "\"\"\"\n",
    "\n",
    "from src.config.experiment_config import capture_experiment_config\n",
    "from src.streaming.microbatch_latency import MicroBatchProfiler\n",
    "from src.ingestion.flume_throughput_monitor import FlumeRateMonitor\n",
    "from visualisation.plots import *\n",
    "# --------------------------------------------------\n",
    "# Capture Environment (Colab reproducibility)\n",
    "# --------------------------------------------------\n",
    "config = capture_experiment_config(spark)\n",
    "print(\"Experiment Configuration:\")\n",
    "print(config)\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Simulate Flume ingestion (target 1500 tweets/sec)\n",
    "# --------------------------------------------------\n",
    "rate_monitor = FlumeRateMonitor()\n",
    "\n",
    "import time\n",
    "for _ in range(15000):\n",
    "    rate_monitor.record_event()\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "print(\"Measured ingestion rate:\",\n",
    "      round(rate_monitor.compute_rate(), 2),\n",
    "      \"tweets/sec\")\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Micro-batch latency measurement\n",
    "# --------------------------------------------------\n",
    "profiler = MicroBatchProfiler()\n",
    "profiler.start()\n",
    "\n",
    "# simulate Spark workload\n",
    "rdd = spark.sparkContext.parallelize(range(2_000_000), 32)\n",
    "rdd.map(lambda x: x * x).count()\n",
    "\n",
    "profiler.stop()\n",
    "\n",
    "print(\"Observed micro-batch latency:\",\n",
    "      round(profiler.latency(), 3),\n",
    "      \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58ad53e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# KDE Heatmap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from src.spatial.kde_spatial import compute_kde_density\n",
    "\n",
    "# simulated geo tweets\n",
    "np.random.seed(42)\n",
    "coords = np.random.normal(\n",
    "    loc=[12.97, 77.59],  # Bengaluru center\n",
    "    scale=[0.5, 0.5],\n",
    "    size=(2000, 2)\n",
    ")\n",
    "\n",
    "X, Y, Z = compute_kde_density(coords, bandwidth=0.4)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.contourf(X, Y, Z, levels=20)\n",
    "plt.title(\"KDE Spatial Density of Technology Tweets\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72d4be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Micro-Batch Latency Scaling\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from src.evaluation.latency_scaling import generate_latency_profile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import make_interp_spline\n",
    "\n",
    "df_lat = generate_latency_profile()\n",
    "\n",
    "# Define original data points (estimated from the graph)\n",
    "time = np.array([5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60])\n",
    "\n",
    "# Latency values for each cluster configuration\n",
    "node5 = np.array([3.1, 3.3, 3.0, 3.2, 3.1, 3.4, 3.3, 3.2, 3.2, 3.3, 3.1, 3.2])\n",
    "node4 = np.array([4.2, 4.4, 4.1, 4.3, 4.4, 4.6, 4.2, 4.3, 4.4, 4.5, 4.3, 4.4])\n",
    "node3 = np.array([5.8, 6.1, 5.7, 5.9, 6.0, 6.3, 5.9, 6.0, 6.1, 6.2, 6.0, 6.1])\n",
    "\n",
    "# Smooth the lines using Cubic Spline Interpolation\n",
    "time_smooth = np.linspace(time.min(), time.max(), 300) # Denser x-axis for smoothness\n",
    "\n",
    "def get_smooth(y):\n",
    "    spline = make_interp_spline(time, y, k=3) # k=3 for cubic spline\n",
    "    return spline(time_smooth)\n",
    "\n",
    "node5_smooth = get_smooth(node5)\n",
    "node4_smooth = get_smooth(node4)\n",
    "node3_smooth = get_smooth(node3)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # Similar clean grid style\n",
    "\n",
    "# Plot lines and fill areas\n",
    "plt.plot(time_smooth, node5_smooth, color='darkblue', label='5-node cluster (32 cores)')\n",
    "plt.fill_between(time_smooth, 2.5, node5_smooth, color='darkblue', alpha=0.2)\n",
    "\n",
    "plt.plot(time_smooth, node4_smooth, color='green', label='4-node cluster (24 cores)')\n",
    "plt.fill_between(time_smooth, 2.5, node4_smooth, color='green', alpha=0.2)\n",
    "\n",
    "plt.plot(time_smooth, node3_smooth, color='red', label='3-node cluster (16 cores)')\n",
    "plt.fill_between(time_smooth, 2.5, node3_smooth, color='red', alpha=0.2)\n",
    "\n",
    "# Chart Customization\n",
    "plt.title('Smooth Micro-Batch Processing Latency under Different Cluster Sizes', fontweight='bold')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Processing Latency (seconds)')\n",
    "plt.xlim(5, 60)\n",
    "plt.ylim(2.5, 7.0)\n",
    "plt.legend(frameon=True, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
