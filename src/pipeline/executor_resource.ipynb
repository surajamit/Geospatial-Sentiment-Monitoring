{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db77fa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Spark Session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Executor-Profiling\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", 32)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106cab7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import Profiler\n",
    "\n",
    "from src.evaluation.executor_profiler import (\n",
    "    get_executor_info,\n",
    "    monitor_resources\n",
    ")\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5ce99",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Executor Inventory\n",
    "\n",
    "executors = get_executor_info(spark)\n",
    "df_exec = pd.DataFrame(executors)\n",
    "\n",
    "print(\"Executor Configuration:\")\n",
    "df_exec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d610c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run Workload + Monitor\n",
    "\n",
    "\"\"\"\n",
    "Simulated workload similar to tweet processing.\n",
    "\"\"\"\n",
    "\n",
    "import threading\n",
    "\n",
    "def run_workload():\n",
    "    rdd = spark.sparkContext.parallelize(range(5_000_000), 32)\n",
    "    rdd.map(lambda x: x * x).count()\n",
    "\n",
    "# start workload\n",
    "t = threading.Thread(target=run_workload)\n",
    "t.start()\n",
    "\n",
    "# monitor resources during execution\n",
    "snapshots = monitor_resources(interval_sec=2, duration_sec=30)\n",
    "\n",
    "t.join()\n",
    "\n",
    "df_usage = pd.DataFrame(snapshots)\n",
    "df_usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0275a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# CPU Utilization Plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.plot(df_usage[\"cpu_percent\"], marker=\"o\")\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"CPU Utilization (%)\")\n",
    "plt.title(\"Driver CPU Utilization During Distributed Execution\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f641e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Memory Utilization Plot\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "plt.plot(df_usage[\"memory_percent\"], marker=\"s\")\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Memory Utilization (%)\")\n",
    "plt.title(\"Driver Memory Usage During Spark Processing\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
